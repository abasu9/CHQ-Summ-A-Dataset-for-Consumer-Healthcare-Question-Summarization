# CHQ-Summ Evaluation Configuration

models:
  bart:
    model_name: facebook/bart-large
    max_input_length: 1024
    max_target_length: 150
    min_target_length: 10
    num_beams: 6
    length_penalty: 2.0
  
  pegasus:
    model_name: google/pegasus-large
    max_input_length: 512
    max_target_length: 128
    min_target_length: 10
    num_beams: 6
    length_penalty: 2.0
  
  t5:
    model_name: t5-large
    max_input_length: 512
    max_target_length: 150
    min_target_length: 10
    num_beams: 6
    length_penalty: 2.0
  
  prophetnet:
    model_name: microsoft/prophetnet-large-uncased
    max_input_length: 512
    max_target_length: 150
    min_target_length: 10
    num_beams: 6
    length_penalty: 2.0

evaluation:
  methods:
    - standard
    - chain_of_density
    - hierarchical
    - element_aware
  
  num_shots: [0]  # Add [0, 2, 5] for few-shot
  
  metrics:
    - rouge_l
    - bertscore
    - semantic_coherence
    - entailment
    - summac
    - qe_overlap
    - entity_preservation
  
  batch_size: 1
  num_samples: null  # null = all samples

data:
  data_dir: data/
  xml_file: yahool6.xml
  train_file: train.json
  val_file: val.json
  test_file: test.json

output:
  results_dir: results/
  save_predictions: true
  save_metrics: true
  verbose: true

device:
  use_cuda: true
  device_id: 0
